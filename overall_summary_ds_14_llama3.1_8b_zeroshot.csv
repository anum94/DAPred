,Unnamed: 0.24,Unnamed: 0.23,Unnamed: 0.22,Unnamed: 0.21,Unnamed: 0.20,Unnamed: 0.19,Unnamed: 0.18,Unnamed: 0.17,Unnamed: 0.16,Unnamed: 0.15,Unnamed: 0.14,Unnamed: 0.13,Unnamed: 0.12,Unnamed: 0.11,Unnamed: 0.10,Unnamed: 0.9,Unnamed: 0.8,Unnamed: 0.7,Unnamed: 0.6,Unnamed: 0.5,Unnamed: 0.4,Unnamed: 0.3,Unnamed: 0.2,Unnamed: 0.1,Unnamed: 0,lay_summarization,use_togetherai,use_openai,device_map,load_in_4bit,load_in_8bit,eval_metrics,method,exec_kwargs,model_hf_key,batch_size,max_new_tokens,few_shot_examples,max_length,min_input_size,max_sample_size,samples,preview,split,dataset_name,run_id,model,prompt,bert_precision,bert_recall,bert_f1,rouge1,rouge2,rougeL,rougeLsum,vocab_overlap,Relevance,Coherence,Consistency,Fluency,fs_wiki,fs_grounded
0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,test,pubmed,/home/esor/Desktop/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_pubmed_test_2024-10-29_20-24-35/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_pubmed_test_2024-10-29_20-24-35.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8451592725515366,0.8497091805934907,0.8472490000724793,0.3784560240544243,0.135888356448625,0.213662303151192,0.3121737850206325,21.82984607017017,4.15,3.95,4.44,3.0,0.0,0.9666245156367764
1,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,test,govreport,/home/esor/Desktop/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_govreport_test_2024-10-29_22-20-44/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_govreport_test_2024-10-29_22-20-44.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8719064646959305,0.8513292908668518,0.8614235347509385,0.4147326448652556,0.1795232065165202,0.2260332171367803,0.2711502928220632,26.1276014324234,3.42,3.39,3.46,2.98,0.0,0.9616459376269754
2,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,0.0,,True,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,test,wispermed,/home/esor/Desktop/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_wispermed_test_2024-10-30_00-06-11/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_wispermed_test_2024-10-30_00-06-11.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8537901818752289,0.8497839325666428,0.8516950613260269,0.4541581306899197,0.1498310186092768,0.2332651111371019,0.276590057171133,21.887086575580835,3.85,3.85,3.79,3.0,0.0,0.9538359032521424
3,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,0.0,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,arxiv,/home/esor/Desktop/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_arxiv_test_2024-10-30_02-19-35/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_arxiv_test_2024-10-30_02-19-35.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8371114236116409,0.8377139949798584,0.837260992527008,0.3708997602353639,0.1289370629769906,0.2119253017306124,0.3137826066270367,22.830383500954778,4.01,3.97,4.08,3.0,0.0,0.9508739131145728
4,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,0.0,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,bigpatent,/home/esor/Desktop/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_bigpatent_test_2024-10-30_05-51-05/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_bigpatent_test_2024-10-30_05-51-05.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8313118880987167,0.8817125314474106,0.855647684931755,0.2667797654134522,0.1089286253356318,0.1860418350327686,0.2086270567366406,20.99859378479349,4.05,4.02,4.43,3.0,0.0,0.9742458034933588
5,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,0.0,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,billsum,/home/esor/Desktop/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_billsum_test_2024-10-30_07-47-34/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_billsum_test_2024-10-30_07-47-34.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8634775125980377,0.8829920262098312,0.8728068375587463,0.5059831074712502,0.2599804313076249,0.3341599970090217,0.4099136819919421,24.243638693257495,4.28,4.0,4.46,3.0,0.0,0.962216613620726
6,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,0.0,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,arxiv,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_arxiv_train_2024-10-30_10-15-28/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_arxiv_train_2024-10-30_10-15-28.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8353504115343093,0.8342202997207642,0.8344744801521301,0.3075635676606064,0.0969442885609252,0.1847557307176148,0.2378216682664396,23.147561440810733,4.09,3.87,4.21,3.0,0.0,0.9381054023658923
7,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,0.0,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,cnndm,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_cnndm_train_2024-10-30_12-40-35/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_cnndm_train_2024-10-30_12-40-35.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8775618952512741,0.8856431531906128,0.8813673269748687,0.3707189723959821,0.1467517226665982,0.2667341070213216,0.2667161554095387,19.986949290532497,2.07,0.87,1.85,3.0,0.0,0.6094931891957251
8,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,0.0,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,govreport,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_govreport_train_2024-10-30_13-32-37/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_govreport_train_2024-10-30_13-32-37.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8660331088304519,0.8657244491577148,0.8656413030624389,0.4786932261999886,0.2138615185242635,0.2708919663164526,0.3156258403805579,25.482177779002132,4.01,3.89,4.07,3.0,0.0,0.9431835826263698
9,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,0.0,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,samsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_samsum_train_2024-10-30_15-59-15/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_samsum_train_2024-10-30_15-59-15.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8604873645305634,0.9195656508207322,0.8889066821336746,0.2919408638510552,0.1038414433226202,0.2627905342842159,0.2626792036129907,17.574550482513764,0.99,0.06,0.18,2.93,0.0,0.3065625874531371
10,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,0.0,,,,,,,,,,True,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,train,wispermed,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_wispermed_train_2024-10-30_17-59-33/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_wispermed_train_2024-10-30_17-59-33.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8535583788156509,0.8490964770317078,0.8512261146306992,0.4495129686526027,0.1492685929096389,0.2340911061467914,0.2759219727795904,22.243876787738873,3.81,3.81,3.77,3.0,0.0,0.960247019870411
11,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,0.0,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,train,pubmed,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_pubmed_train_2024-10-31_00-06-35/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_pubmed_train_2024-10-31_00-06-35.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8372135245800019,0.8410811167955399,0.8390237563848495,0.3168915026184765,0.102176958372183,0.1966389288365808,0.2485268223853495,21.916564939227506,3.97,3.28,4.3,3.0,0.0,0.9555809387998784
12,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,0.0,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,train,billsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_billsum_train_2024-10-31_09-50-33/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_billsum_train_2024-10-31_09-50-33.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8629366689920426,0.8831701201200485,0.8726658695936202,0.4954359784259821,0.2511415698059293,0.3225801243038715,0.4003155127998132,24.238437995915657,4.4,4.08,4.42,3.0,0.0,0.9548553042875392
13,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,0.0,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,test,samsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_samsum_test_2024-10-31_11-10-46/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_samsum_test_2024-10-31_11-10-46.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8764901053905487,0.9231383210420608,0.8990976285934448,0.3725022981509777,0.1595226180445286,0.3137834819385802,0.3136826663278205,17.728176403219162,1.72,0.99,1.19,3.0,0.0,0.4576442580980789
14,14.0,14.0,14.0,14.0,14.0,14.0,14.0,14.0,14.0,14.0,14.0,0.0,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,test,samsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_samsum_test_2024-10-31_11-54-49/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_samsum_test_2024-10-31_11-54-49.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8765851926803588,0.9234662628173828,0.899300844669342,0.3657752764700109,0.1530237031727787,0.3054856064662772,0.305612189591361,17.733062356488166,1.69,0.73,0.82,2.99,0.0,0.441971080169173
15,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,0.0,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,8192,0,100,max,False,test,cnndm,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_cnndm_test_2024-10-31_12-26-29/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_cnndm_test_2024-10-31_12-26-29.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8742229223251343,0.8965571165084839,0.8850847697257995,0.4076972621893632,0.1758338149545631,0.28109575278569,0.2822111379608758,19.036226630305254,4.12,3.4,4.18,3.0,0.0,0.9479436873833632
16,16.0,16.0,16.0,16.0,16.0,16.0,16.0,16.0,16.0,0.0,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,bigpatent,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_bigpatent_train_2024-10-31_22-32-15/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_bigpatent_train_2024-10-31_22-32-15.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8304957467317581,0.8841246801614762,0.8563973075151443,0.2444231913636037,0.1009170162148777,0.1746017180572573,0.1968113053588902,21.030098563687325,4.1,4.01,4.5,3.0,0.0,0.9716204196756364
17,17.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,0.0,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,newsroom,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_newsroom_train_2024-11-01_10-25-41/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_newsroom_train_2024-11-01_10-25-41.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8407835853099823,0.8541952437162399,0.8472060120105743,0.1740760741273012,0.0579398161358154,0.1404697107571176,0.1407907820345523,19.15425947997877,1.57,1.39,0.75,2.9,0.0,0.5773916837490518
18,18.0,18.0,18.0,18.0,18.0,18.0,18.0,0.0,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,newsroom,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_newsroom_test_2024-11-01_11-10-56/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_newsroom_test_2024-11-01_11-10-56.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8464066565036774,0.8540424263477325,0.849948992729187,0.2066976233132956,0.0703190905947605,0.1589138395101066,0.1598540839877607,18.52618232403555,1.41,1.18,0.71,2.93,0.0,0.5567356502942095
19,19.0,19.0,19.0,19.0,19.0,19.0,0.0,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,dialogsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_dialogsum_test_2024-11-06_16-42-09/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_dialogsum_test_2024-11-06_16-42-09.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8663193434476852,0.8776495105028153,0.8717647975683213,0.2204303701340271,0.072095505502857,0.1752629060617271,0.1760221198632474,18.12441044360433,0.95,0.92,0.67,2.99,,0.5966400330158171
20,20.0,20.0,20.0,20.0,20.0,0.0,,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,dialogsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_dialogsum_train_2024-11-06_17-54-41/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_dialogsum_train_2024-11-06_17-54-41.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8726603865623475,0.8835662382841111,0.8779531413316727,0.2362880369646884,0.0836008673462638,0.1973816176016516,0.1976064655786642,18.05159489249677,0.32,0.16,0.28,2.98,,0.5646955092059901
21,21.0,21.0,21.0,21.0,0.0,,,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,aclsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_aclsum_train_2024-11-06_23-37-42/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_aclsum_train_2024-11-06_23-37-42.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8488794475793838,0.8898642790317536,0.8688478720188141,0.3625270543932897,0.1430808312594569,0.2166161171296314,0.3079468593839137,29.49969869516229,4.09,4.02,4.27,3.0,,0.9776062731934878
22,22.0,22.0,22.0,0.0,,,,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,aclsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_aclsum_test_2024-11-07_11-06-11/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_aclsum_test_2024-11-07_11-06-11.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8492022222280502,0.8880372017621994,0.8681435453891754,0.3616715647583434,0.1453831289809803,0.2253075320461237,0.3093170475366159,29.711453914139952,4.08,4.02,4.37,3.0,,0.9746685368789084
23,23.0,23.0,0.0,,,,,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,gigaword,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_gigaword_train_2024-11-07_13-13-20/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_gigaword_train_2024-11-07_13-13-20.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8230928653478622,0.8223689329624176,0.8224523323774338,0.1051486405020258,0.0162091776578815,0.0903470206590424,0.0901181886005389,24.95055349274692,0.13,0.0,0.0,2.41,,0.1221121216801734
24,24.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,gigaword,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_gigaword_test_2024-11-07_14-34-57/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_gigaword_test_2024-11-07_14-34-57.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8302098762989044,0.8341106426715851,0.8319220978021622,0.128850118554099,0.0417291630932295,0.1193010295362266,0.1199073148043434,25.643778539237324,0.64,0.04,0.0,2.74,,0.1927191327606539
25,0.0,,,,,,,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,train,xlsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_xlsum_train_2024-11-07_15-11-46/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_xlsum_train_2024-11-07_15-11-46.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8492346203327179,0.8695636665821076,0.8591392636299133,0.1652289601628447,0.0251218293985024,0.127777278493588,0.1274851563704414,20.405566301100045,4.13,3.99,4.16,2.8,,0.4182281085294282
0,,,,,,,,,,,,,,,,,,,,,,,,,,False,True,False,auto,False,False,"['bertscore', 'rogue', 'vocab_overlap', 'llm_eval', 'fact_score']",,{},meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo,1,256,False,4096,0,100,max,False,test,xlsum,/Users/anumafzal/PycharmProjects/domain-adaptation/results/summarization_csv/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_xlsum_test_2024-11-07_15-44-07/MODEL_meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo_0-SHOT_xlsum_test_2024-11-07_15-44-07.csv,meta-llama-Meta-Llama-3.1-8B-Instruct-Turbo,"Proceed to summarize the following text. 
 TEXT : {} 
 Summary: 
",0.8422674089670181,0.8931749927997589,0.8668949860334396,0.20252405304479992,0.04367762236948676,0.1439970248677334,0.14350534126318232,20.116371793681235,4.9,4.82,4.92,2.98,,0.8678620300510292
